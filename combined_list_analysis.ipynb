{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE INTO FOLDER AND CREATE IMAGES FOLDER\n",
    "# Start in satimage/data\n",
    "import csv\n",
    "import requests\n",
    "from PIL import Image\n",
    "import os, sys \n",
    "\n",
    "YOUR_API_KEY = \"<API_KEY>\"\n",
    "BASE_URL = \"https://maps.googleapis.com/maps/api/staticmap?\"\n",
    "#URL = https://maps.googleapis.com/maps/api/staticmap?center=26.7045146,81.0133491&zoom=16&size=1920x1920&maptype=satellite&key=AIzaSyA5o8h8Ag9XwpDQG7jsYCXk1gIjqxAltYo\n",
    "zoom = 16\n",
    "file_name = 'district_list.csv'\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "     \n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        district_file = 'region_info_filled_' + district + '.csv'\n",
    "        with open(district_file,'r') as csv_file:\n",
    "            csv_reader2 = csv.DictReader(csv_file)\n",
    "\n",
    "            image_path = district + '/images'\n",
    "            %cd {image_path}\n",
    "\n",
    "            for line in csv_reader2:\n",
    "                vill_name = line['village_code']\n",
    "                file_name = \"%s.png\" %vill_name\n",
    "                cent_lat = line['centre_lat']\n",
    "                cent_long = line['centre_long']\n",
    "                URL = BASE_URL+\"center=\"+str(cent_lat)+\",\"+str(cent_long)+\"&zoom=\"+str(zoom)+\"&size=1920x1920&maptype=satellite&scale=2&key=\"+YOUR_API_KEY\n",
    "                response = requests.get(URL)\n",
    "                if response.status_code == 200:\n",
    "                    with open(file_name, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    im = Image.open(file_name)\n",
    "                    imResize = im.resize((1920,1920), Image.ANTIALIAS)\n",
    "                    %cd ../new_images    \n",
    "                    imResize.save(file_name,'png')\n",
    "                    %cd ../images\n",
    "            %cd ..\n",
    "        %cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION\n",
    "# Create images and new images folders\n",
    "import csv\n",
    "file_name = 'district_list.csv'\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "     \n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        %cd {district}\n",
    "        %mkdir images\n",
    "        %mkdir new_images\n",
    "        %cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIZE\n",
    "from PIL import Image\n",
    "import os, sys \n",
    "\n",
    "path = os.path.expanduser('./images/')\n",
    "new_path = os.path.expanduser('./new_images/')\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "for item in dirs:\n",
    "    imFile = path+item\n",
    "    if (os.path.isfile(imFile) and item !='.DS_Store'):\n",
    "        im = Image.open(imFile)\n",
    "        f, e = os.path.splitext(new_path+item)\n",
    "        imResize = im.resize((1920,1920), Image.ANTIALIAS)\n",
    "        imResize.save(f + '.png','png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PREDICTIONS - Development Indicators \n",
    "\n",
    "import util\n",
    "import satimage\n",
    "model = util.restore_model('../models/developmental/best_model_architecture.json', '../models/developmental/best_model_weights.h5')\n",
    "file_name = 'district_list.csv' # csv file with list of 38 districts\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for line in csv_reader: # Iterate through districts, for each district generate predictions\n",
    "        district = line['District']\n",
    "        path1 = '../data/'+district+'/new_images' # Path to satellite images\n",
    "        path2 = '../data/'+district+'/predicted_developmental.csv' # Path to csv file to save predictiosns\n",
    "        predictions = satimage.generate_predictions(model, path1 , path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EVALUATE PREDICTIONS - check income classification \n",
    "\n",
    "import secc\n",
    "import csv\n",
    "import prediction_statistics\n",
    "import pandas as pd\n",
    "file_name = 'district_list.csv'\n",
    "results = []\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    num_wrong = 0\n",
    "    num_right = 0\n",
    "    num_subdist = 0\n",
    "    \n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        print(district) \n",
    "        pathB = '../data_backup/'+district+'/pd_subdistrict_income.csv'\n",
    "        pathA = '../data_backup/subdistrict_income/data_subdistrict_income_'+district+'.csv'\n",
    "        num_right,num_wrong, num_subdist = prediction_statistics.check_income_category(pathA,pathB, num_right,num_wrong, num_subdist)\n",
    "        results.append([district, num_right, num_wrong])\n",
    "    df_category = pd.DataFrame(results, columns = ['District','Corr_pred', 'Incorr_pred'])\n",
    "    df_category.to_csv('../results/check_income_category.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# EVALUATE PREDICTIONS - Calculate and save pearsonr coefficients\n",
    "\n",
    "%cd code\n",
    "import secc\n",
    "import csv\n",
    "import prediction_statistics\n",
    "import pandas as pd\n",
    "file_name = 'district_list.csv'\n",
    "results = []\n",
    "thresh_results = []\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        print(district) \n",
    "        pathA = '../data_backup/subdistrict_income/data_subdistrict_income_'+district+'.csv'\n",
    "        pathB = '../data_backup/'+district+'/pd_subdistrict_income.csv'\n",
    "        coeff1, coeff2, coeff3, thresh_vals = prediction_statistics.compare_income_predictions(pathA,pathB)\n",
    "        \n",
    "        results.append([district, coeff1, coeff2, coeff3])\n",
    "        pearson_coeff = pd.DataFrame(results, columns = ['District','class_0', 'class_1','class_2'])\n",
    "    pearson_coeff.to_csv('../results/pearson_coeffs_pd_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE PREDICTIONS - Calculate Mean Squared Error for income predictions \n",
    "\n",
    "import csv\n",
    "import prediction_statistics\n",
    "import pandas as pd \n",
    "\n",
    "file_name = 'district_list.csv'\n",
    "results = []\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        print(district) \n",
    "        pathA = '../data_backup/subdistrict_income/data_subdistrict_income_'+district+'.csv'\n",
    "        pathB = '../data_backup/'+district+'/pd_subdistrict_income.csv'\n",
    "        mse0,mse1,mse2 = prediction_statistics.mean_sqr_err_in(pathA,pathB)\n",
    "        r2_0,r2_1,r2_2 = prediction_statistics.r2(pathA,pathB)\n",
    "        results.append([district, mse0, mse1, mse2,r2_0,r2_1,r2_2])\n",
    "    df = pd.DataFrame(results, columns = ['District','MSE_0', 'MSE_1','MSE_2','R2_0','R2_1','R2_2'])\n",
    "    df.to_csv('../results/pd_census_MSE_R2_results.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EVALUATE PREDICTIONS - Count number of majority classes per group \n",
    "%cd code\n",
    "import secc\n",
    "import csv\n",
    "import prediction_statistics\n",
    "import pandas as pd\n",
    "file_name = 'district_list.csv'\n",
    "results = []\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    num_0 = 0\n",
    "    num_1 = 0\n",
    "    num_2 = 0\n",
    "    \n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        print(district) \n",
    "        #pathA = '../data_backup/subdistrict_income/data_subdistrict_income_'+district+'.csv'\n",
    "        pathB = '../data_backup/'+district+'/pd_subdistrict_income.csv'\n",
    "        num_0, num_1,num_2= prediction_statistics.count_income_category(pathB,num_0, num_1,num_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check development classification\n",
    "\n",
    "import sklearn.metrics as sk\n",
    "import pandas as pd\n",
    "import csv\n",
    "file_name = 'district_list.csv'\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        print(district) \n",
    "        pathB = '../data_backup/'+district+'/predicted_developmental.csv'\n",
    "        pathA = '../data_backup/census_data_'+district+'.csv'\n",
    "        data_census = pd.read_csv(pathA, index_col=False)\n",
    "        data_predicted = pd.read_csv(pathB, index_col=False)\n",
    "        print(sk.classification_report(data_census,data_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EVALUATE PREDICTIONS - Calculate Mean Squared Error for development predictions\n",
    "%cd code\n",
    "import csv\n",
    "import prediction_statistics\n",
    "import pandas as pd \n",
    "\n",
    "file_name = 'district_list.csv'\n",
    "dev_df = pd.DataFrame()\n",
    "results = []\n",
    "districts = []\n",
    "\n",
    "with open(file_name,'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for line in csv_reader:\n",
    "        district = line['District']\n",
    "        print(district)\n",
    "        districts.append(district)\n",
    "        pathD = '../data_backup/'+district+'/predicted_developmental.csv'\n",
    "        pathC = '../data_backup/census_data_'+district+'.csv'\n",
    "        mse_r2_data = prediction_statistics.mean_sqr_err_dev(pathC, pathD)\n",
    "        mse_r2_series = pd.Series(mse_r2_data)\n",
    "        dev_df.append(mse_r2_series.T,ignore_index=True)\n",
    "        results.append(mse_r2_data)\n",
    "df_dev = pd.DataFrame(results,index = districts, columns = ['mse_0','mse_1','mse_2','r2_0','r2_1','r2_2'])\n",
    "df_dev.to_csv('../results/MSE_R2_dev_results_dev_comb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
